{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import random\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = '091902'\n",
    "# input_file = \"combined_20230919061630_Himawari_202309190610.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把科學記號改成十進位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import decimal\n",
    "# \n",
    "# # 讀取CSV文件，確保資料的精度\n",
    "# df = pd.read_csv('data/combined_dataset_all.csv', encoding='utf-8-sig', dtype=str)\n",
    "# \n",
    "# # 將Chlorophyll欄位轉換為不使用科學記號的小數形式\n",
    "# df['Chlorophyll'] = df['Chlorophyll'].apply(lambda x: format(decimal.Decimal(x), 'f'))\n",
    "# \n",
    "# # 輸出篩選後的結果到原本的CSV文件\n",
    "# df.to_csv('data/combined_dataset_all.csv', index=False, encoding='utf-8-sig')\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先取出1000000筆來train看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取CSV文件\n",
    "combined_df = pd.read_csv(f\"data_all/{data_set}.csv\")\n",
    "\n",
    "# 隨機選取10000筆資料\n",
    "sampled_df = combined_df.sample(n=1000000, random_state=1)\n",
    "\n",
    "# 保存為新的CSV文件\n",
    "sampled_df.to_csv(\"data_all/train_temp/train_combined_dataset_all.csv\", index=False)\n",
    "\n",
    "print(\"已成功從 combined_dataset_all.csv 中選取 1000000 筆資料並保存到 data/train_combined_dataset_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_all/train_temp/train_combined_dataset_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe()\n",
    "data.shape\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output filtered csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇所需的列\n",
    "selected_columns = ['Albedo_01', 'Albedo_02', 'Albedo_03', 'Albedo_04', 'Chlorophyll']\n",
    "\n",
    "# 過濾數據\n",
    "filtered_data = data[selected_columns]\n",
    "\n",
    "## 重命名列，去掉 '2km_'\n",
    "#filtered_data.columns = ['albedo_01', 'albedo_02', 'albedo_03', 'albedo_04', 'Chlorophyll']\n",
    "#\n",
    "# 將過濾後的數據寫入新的CSV文件\n",
    "filtered_data.to_csv(\"data_all/train_temp/train_nn_filtered_data.csv\", index=False)\n",
    "\n",
    "print(\"新的 CSV 文件已成功輸出，文件名為 data_all/train_temp/train_nn_filtered_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "移除包含 '<' 符號的行(因非海保署資料，故已不再需要)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# \n",
    "# # 讀取CSV文件，確保資料的精度\n",
    "# df = pd.read_csv('data/train_nn_filtered_data.csv', encoding='utf-8-sig', dtype=str)\n",
    "# \n",
    "# # 移除包含 '<' 符號的行\n",
    "# filtered_df = df[~df.apply(lambda row: row.str.contains('<|,').any(), axis=1)]\n",
    "# \n",
    "# # 輸出篩選後的結果到新的CSV文件\n",
    "# filtered_df.to_csv('data/train_filtered_and_trimmed_data.csv', index=False, encoding='utf-8-sig')\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "科學記號轉小數看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import decimal\n",
    "\n",
    "# 讀取CSV文件，確保資料的精度\n",
    "df = pd.read_csv('data_all/train_temp/train_nn_filtered_data.csv', encoding='utf-8-sig', dtype=str)\n",
    "\n",
    "# 將Chlorophyll欄位轉換為不使用科學記號的小數形式\n",
    "df['Chlorophyll'] = df['Chlorophyll'].apply(lambda x: format(decimal.Decimal(x), 'f'))\n",
    "\n",
    "# 輸出篩選後的結果到原本的CSV文件\n",
    "df.to_csv('data_all/train_temp/train_nn_filtered_data.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料的描述以及葉綠素值的分布圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 讀取CSV文件\n",
    "data = pd.read_csv(\"data_all/train_temp/train_nn_filtered_data.csv\")\n",
    "\n",
    "# 確認數據的資訊\n",
    "data.info()\n",
    "\n",
    "# 顯示基本統計描述\n",
    "print(data.describe())\n",
    "\n",
    "# 顯示數據的形狀\n",
    "print(data.shape)\n",
    "\n",
    "# 顯示數據的欄位名稱\n",
    "print(data.columns)\n",
    "\n",
    "# 畫出Chlorophyll的分布圖\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['Chlorophyll'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Chlorophyll')\n",
    "plt.xlabel('Chlorophyll')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除極端值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 讀取CSV文件\n",
    "data = pd.read_csv(\"data_all/train_temp/train_nn_filtered_data.csv\")\n",
    "\n",
    "# 顯示原始數據的描述性統計量\n",
    "print(\"原始數據的描述性統計量:\")\n",
    "print(data['Chlorophyll'].describe())\n",
    "\n",
    "# 去除Chlorophyll值大於10的極端值\n",
    "data_filtered = data[data['Chlorophyll'] <= 30]\n",
    "\n",
    "# 顯示過濾後數據的描述性統計量\n",
    "print(\"\\n過濾後數據的描述性統計量:\")\n",
    "print(data_filtered['Chlorophyll'].describe())\n",
    "\n",
    "# 畫出過濾後Chlorophyll的分布圖\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.hist(data_filtered['Chlorophyll'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Chlorophyll (Filtered)')\n",
    "plt.xlabel('Chlorophyll')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 將過濾後的數據保存到新的CSV文件中\n",
    "data_filtered.to_csv(\"data_all/train_temp/train_nn_filtered_data_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered.Chlorophyll.count())\n",
    "print(data_filtered.Albedo_01.count())\n",
    "print(data_filtered.Albedo_02.count())\n",
    "print(data_filtered.Albedo_03.count())\n",
    "print(data_filtered.Albedo_04.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_filtered\n",
    "train.info()\n",
    "train.Chlorophyll.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Chlorophyll', axis=1)\n",
    "y = train.Chlorophyll\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scale the data to make it easier for the model to learn\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "\n",
    "random_seed = random.randint(1, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_ratio, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,)],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'activation': ['tanh', 'relu']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an MLPRegressor instance\n",
    "# mlp = MLPRegressor(solver='sgd', max_iter=200,\n",
    "#                    n_iter_no_change=10, tol=0.0001, verbose=1)\n",
    "# \n",
    "# # Create a GridSearchCV instance\n",
    "# grid_mlp = GridSearchCV(\n",
    "#     mlp, param_grid, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1, cv=5)\n",
    "# \n",
    "# # Fit the grid search to the data\n",
    "# grid_mlp.fit(X_train, y_train)\n",
    "# \n",
    "# # Get the best estimator\n",
    "# optimized_mlp = grid_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN模型第二版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (100, 50), (100, 100, 50)],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
    "    'learning_rate_init': [0.0001, 0.001, 0.01, 0.05],\n",
    "    'activation': ['tanh', 'relu']\n",
    "}\n",
    "mlp = MLPRegressor(solver='adam', max_iter=500, n_iter_no_change=20, tol=0.0001, verbose=1)\n",
    "grid_mlp = GridSearchCV(mlp, param_grid, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1, cv=5)\n",
    "grid_mlp.fit(X_train, y_train)\n",
    "# Get the best estimator\n",
    "optimized_mlp = grid_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters found by the grid search\n",
    "print(\"MLP best parameters:\", grid_mlp.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "MLP_train_pred = optimized_mlp.predict(X_train)\n",
    "MLP_test_pred = optimized_mlp.predict(X_test)\n",
    "\n",
    "\n",
    "# 將預測結果限制在0到30之間\n",
    "MLP_train_pred = np.clip(MLP_train_pred, 0, 30)\n",
    "MLP_test_pred = np.clip(MLP_test_pred, 0, 30)\n",
    "\n",
    "# Calculate the desired metrics\n",
    "train_mae = mean_absolute_error(y_train, MLP_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, MLP_test_pred)\n",
    "train_rmse = sqrt(mean_squared_error(y_train, MLP_train_pred))\n",
    "test_rmse = sqrt(mean_squared_error(y_test, MLP_test_pred))\n",
    "train_r2 = r2_score(y_train, MLP_train_pred)\n",
    "test_r2 = r2_score(y_test, MLP_test_pred)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Train MAE: {train_mae}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")\n",
    "print(f\"Train R2: {train_r2}\")\n",
    "print(f\"Test R2: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already run the previous code and have MLP_train_pred and MLP_test_pred ready\n",
    "\n",
    "# Combine actual and predicted values for train and test sets\n",
    "train_results = pd.DataFrame({'Actual': y_train, 'Predicted': MLP_train_pred})\n",
    "test_results = pd.DataFrame({'Actual': y_test, 'Predicted': MLP_test_pred})\n",
    "\n",
    "# Plot actual vs predicted for the training set\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(train_results['Actual'], train_results['Predicted'], alpha=0.5, color='blue')\n",
    "plt.plot([train_results['Actual'].min(), train_results['Actual'].max()], \n",
    "         [train_results['Actual'].min(), train_results['Actual'].max()], 'r--', lw=2)\n",
    "plt.title('Actual vs Predicted for Training Set')\n",
    "plt.xlabel('Actual Chlorophyll')\n",
    "plt.ylabel('Predicted Chlorophyll')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot actual vs predicted for the test set\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_results['Actual'], test_results['Predicted'], alpha=0.5, color='green')\n",
    "plt.plot([test_results['Actual'].min(), test_results['Actual'].max()], \n",
    "         [test_results['Actual'].min(), test_results['Actual'].max()], 'r--', lw=2)\n",
    "plt.title('Actual vs Predicted for Test Set')\n",
    "plt.xlabel('Actual Chlorophyll')\n",
    "plt.ylabel('Predicted Chlorophyll')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出不同解析度的圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 假設你已經有 y_train, y_test, MLP_train_pred 和 MLP_test_pred 的數據\n",
    "\n",
    "# Combine actual and predicted values for train and test sets\n",
    "train_results = pd.DataFrame({'Actual': y_train, 'Predicted': MLP_train_pred})\n",
    "test_results = pd.DataFrame({'Actual': y_test, 'Predicted': MLP_test_pred})\n",
    "\n",
    "# alpha值的列表\n",
    "alpha_values = [0.5, 0.1, 0.04, 0.01, 0.008, 0.004, 0.002]\n",
    "\n",
    "# 使用迴圈來生成每個alpha值的圖\n",
    "for alpha in alpha_values:\n",
    "    # Plot actual vs predicted for the training set\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(train_results['Actual'], train_results['Predicted'], alpha=alpha, color='blue')\n",
    "    plt.plot([train_results['Actual'].min(), train_results['Actual'].max()], \n",
    "             [train_results['Actual'].min(), train_results['Actual'].max()], 'r--', lw=2)\n",
    "    plt.title(f'Actual vs Predicted for Training Set (alpha={alpha})')\n",
    "    plt.xlabel('Actual Chlorophyll')\n",
    "    plt.ylabel('Predicted Chlorophyll')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot actual vs predicted for the test set\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(test_results['Actual'], test_results['Predicted'], alpha=alpha, color='green')\n",
    "    plt.plot([test_results['Actual'].min(), test_results['Actual'].max()], \n",
    "             [test_results['Actual'].min(), test_results['Actual'].max()], 'r--', lw=2)\n",
    "    plt.title(f'Actual vs Predicted for Test Set (alpha={alpha})')\n",
    "    plt.xlabel('Actual Chlorophyll')\n",
    "    plt.ylabel('Predicted Chlorophyll')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if alpha == 0.002:\n",
    "        ## save picture in the output folder\n",
    "        plt.savefig(f'output/{data_set}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存訓練好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存模型到文件\n",
    "joblib.dump(optimized_mlp, f'model/mlp_regressor_model_{data_set}_30_10%.pkl')\n",
    "print(f\"模型已保存到 'model/mlp_regressor_model_{data_set}_30_10%.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "# 載入已保存的模型\n",
    "loaded_model = joblib.load(f'model/mlp_regressor_model_{data_set}_30_10%.pkl')\n",
    "print(\"模型已成功載入\")\n",
    "\n",
    "# 讀取新的測試資料\n",
    "new_test_data = pd.read_csv(f\"data_all/{data_set}.csv\")\n",
    "\n",
    "# 選擇所需的特徵列\n",
    "selected_columns = ['Albedo_01', 'Albedo_02', 'Albedo_03', 'Albedo_04']\n",
    "X_new_test = new_test_data[selected_columns]\n",
    "\n",
    "# 標準化數據\n",
    "scaler = StandardScaler()\n",
    "X_new_test = scaler.transform(X_new_test)\n",
    "\n",
    "# 使用模型進行預測\n",
    "new_test_predictions = loaded_model.predict(X_new_test)\n",
    "\n",
    "# 將預測結果添加到資料框\n",
    "new_test_data['Predicted_Chlorophyll'] = new_test_predictions\n",
    "\n",
    "# 如果新測試資料包含實際的 Chlorophyll 值，計算評估指標\n",
    "if 'Chlorophyll' in new_test_data.columns:\n",
    "    # 計算誤差度量（MAE, RMSE, R2）\n",
    "    mae = mean_absolute_error(\n",
    "        new_test_data['Chlorophyll'], new_test_predictions)\n",
    "    rmse = sqrt(mean_squared_error(\n",
    "        new_test_data['Chlorophyll'], new_test_predictions))\n",
    "    r2 = r2_score(new_test_data['Chlorophyll'], new_test_predictions)\n",
    "\n",
    "    print(f\"New Test MAE: {mae}\")\n",
    "    print(f\"New Test RMSE: {rmse}\")\n",
    "    print(f\"New Test R2: {r2}\")\n",
    "\n",
    "# 保存預測結果到新的CSV文件\n",
    "new_test_data.to_csv(\"data_output/new_test_predictions.csv\",\n",
    "                     index=False, encoding='utf-8-sig')\n",
    "print(\"新的測試預測結果已保存為 'data/new_test_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
